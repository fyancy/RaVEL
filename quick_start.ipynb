{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-31T11:11:37.715214Z",
     "start_time": "2024-10-31T11:11:35.068582Z"
    }
   },
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "from datasets import SQDataGenerator\n",
    "from my_utils.init_utils import set_seed_torch\n",
    "\n",
    "set_seed_torch(42)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== seed 42 for Trainer ========\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1. Load training data and test data\n",
    "In this part, we load the SEU dataset and split it into training and test sets. In expriments, we use 30% of the data as the training set. Then use a standard normalizer to normalize the data $\\mathbf{x}$. Meanwhile, we calculate the high-order difference of the data $\\mathbf{x}^{n_\\text{df}}$. So we got the prepared training data and test data, which both consist of $[\\mathbf{x}, \\mathbf{x}^{n_\\text{df}}]$.\n",
    "\n",
    "Note: data file should be put in the folder of `datasets` for a normal data loading operation, i.e. `datasets/seu_2speeds_snr-5.npy`. The SEU and SQ data with SNR=-5 are availbel at https://drive.google.com/drive/folders/1GbioYlKtaTG1KRg9b_Krq3p7z00L7pz7?usp=sharing."
   ],
   "id": "1737e9f0b9fe7c1f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T11:11:42.044081Z",
     "start_time": "2024-10-31T11:11:40.596462Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Here we use the SEU/SQ dataset with SNR=-5 as an example\n",
    "SNR = -5\n",
    "# X, Y = SEUDataGenerator(snr=SNR, x_len=1024).data_gen(True)\n",
    "# num_classes = 10\n",
    "# (10, 2, 300, 1, 1024) (10, 2, 300) --> (6000, 1024) (6000, )\n",
    "\n",
    "X, Y = SQDataGenerator(snr=SNR).data_gen(True)\n",
    "num_classes = 7\n",
    "# (7, 144, 1, 2048) (7, 144) --> (1008, 2048) (1008, )\n",
    "\n",
    "print(X.shape, Y.shape)\n",
    "\n",
    "kf = StratifiedShuffleSplit(n_splits=10, train_size=0.3, random_state=42)  # 按类别比例抽样\n",
    "train_test_indices = list(kf.split(X, Y))\n",
    "print(f\"Got {len(train_test_indices)} groups of indices for train and test\")\n",
    "train_indices, test_indices = train_test_indices[0]  # 取第一份数据，这里只演示一次试验\n",
    "X_tra, Y_tra = X[train_indices], Y[train_indices]\n",
    "X_val, Y_val = X[test_indices], Y[test_indices]\n",
    "print(X_tra.shape, Y_tra.shape, X_val.shape, Y_val.shape)"
   ],
   "id": "5cc2ce943522b278",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load SQ data...\n",
      "(1008, 2048) (1008,)\n",
      "Got 10 groups of indices for train and test\n",
      "(302, 2048) (302,) (706, 2048) (706,)\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2. Generate random wavelet kernels\n",
    "- Generate random wavelet kernels $\\mathbf{w}$ with the size of `num_kernels`. We can use the function `fit_kernels` to generate the kernels. \n",
    "- `apply_kernels_multi` is used to apply the kernels to the data $\\mathbf{x}$, and transform the data into the low-dimensional feature space. Here we use four indicators to extract features."
   ],
   "id": "b7c58d4d2fb8b11f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 2.1 RaVEL implemented by several functions\n",
    "You can use the following code to extract random features by random wavelets."
   ],
   "id": "7744b921cfe8203e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T10:39:44.447630Z",
     "start_time": "2024-10-31T10:39:42.695327Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from models.network.ravel.kernel_fit import fit_kernels\n",
    "from models.network.ravel.kernel_apply import apply_kernels_multi\n",
    "\n",
    "# normalize these data\n",
    "n_diff = 3\n",
    "X_tra_norm = (X_tra - X_tra.mean(1, keepdims=True)) / (X_tra.std(1, keepdims=True) + 1e-12)\n",
    "X_val_norm = (X_val - X_val.mean(1, keepdims=True)) / (X_val.std(1, keepdims=True) + 1e-12)\n",
    "X_tra_d, X_val_d = np.diff(X_tra, n_diff), np.diff(X_val, n_diff)\n",
    "print(X_tra_norm.shape, X_val_norm.shape, X_tra_d.shape, X_val_d.shape)\n",
    "\n",
    "num_kernels = 250  # You can try: 1000, 500, 400, 250, 200, 100\n",
    "kernels = fit_kernels(X_tra_norm, num_kernels, multiwavelet=True)\n",
    "X_tra_feat = apply_kernels_multi(X_tra_norm, kernels, cosine_pool=True)\n",
    "X_val_feat = apply_kernels_multi(X_val_norm, kernels, cosine_pool=True)\n",
    "\n",
    "kernels_d = fit_kernels(X_tra_d, num_kernels, multiwavelet=True)\n",
    "X_tra_feat_d = apply_kernels_multi(X_tra_d, kernels_d, cosine_pool=True)\n",
    "X_val_feat_d = apply_kernels_multi(X_val_d, kernels_d, cosine_pool=True)\n",
    "\n",
    "X_tra_feat = np.concatenate([X_tra_feat, X_tra_feat_d], axis=1)\n",
    "X_val_feat = np.concatenate([X_val_feat, X_val_feat_d], axis=1)\n",
    "\n",
    "f_mean, f_std = X_tra_feat.mean(0), X_tra_feat.std(0) + 1e-8\n",
    "X_tra_feat = (X_tra_feat - f_mean) / f_std\n",
    "X_val_feat = (X_val_feat - f_mean) / f_std\n",
    "\n",
    "print(f\"Num_kernel: {num_kernels}*2, train-{X_tra_feat.shape}, valid-{X_val_feat.shape}\")"
   ],
   "id": "c4976f76a9256dd6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(302, 2048) (706, 2048) (302, 2045) (706, 2045)\n",
      "Num_kernel: 250*2, train-(302, 2000), valid-(706, 2000)\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 2.2 RaVEL via Python package\n",
    "\n",
    "You can use the following code to extract random features by random wavelets.\n",
    "Or you can use the following package.\n",
    "`pip install randwave`"
   ],
   "id": "a099ced468643f5b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T12:12:23.175182Z",
     "start_time": "2024-10-31T12:12:21.258775Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# from randwave_source import RandWaveTransform\n",
    "from randwave import RandWaveTransform  # the downloaded python package\n",
    "\n",
    "rwt = RandWaveTransform(num_kernels=250, num_diff=3)\n",
    "X_tra_feat = rwt.fit_transform(X_tra)\n",
    "X_val_feat = rwt.transform(X_val)\n",
    "\n",
    "print(f\"Num_kernel: {rwt.num_kernels}*2, train-{X_tra_feat.shape}, valid-{X_val_feat.shape}\")"
   ],
   "id": "3f5b012ad2aee2a2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num_kernel: 250*2, train-(302, 2000), valid-(706, 2000)\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3. Train a simple MLP model ",
   "id": "f1a2634d922edbd7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T12:12:27.998490Z",
     "start_time": "2024-10-31T12:12:27.607184Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def do_train_single_label_cpu(model, optimizer: torch.optim.Optimizer, loss_fn: torch.nn.modules.loss._Loss,\n",
    "                              train_loader, valid_data, max_epochs, scheduler):\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        for epi, (bx, by) in enumerate(train_loader):\n",
    "            logits = model(bx)\n",
    "            training_loss = loss_fn(logits, by)\n",
    "            training_loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            bx_ind, by_ind = valid_data\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                logits_ind = model(bx_ind)\n",
    "            model.train()\n",
    "            acc_ind = (logits_ind.argmax(1) == by_ind).float().mean().item()\n",
    "            print(f\"[Epoch-{epoch + 1}/{max_epochs}] Test Acc. {acc_ind:.2%}\")\n",
    "\n",
    "    bx_ind, by_ind = valid_data\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits_ind = model(bx_ind)\n",
    "    model.train()\n",
    "\n",
    "    acc_ind = (logits_ind.argmax(1) == by_ind).float().mean().item()\n",
    "    print(f\"\\nTest Acc. {acc_ind:.2%}\")"
   ],
   "id": "46b69c47f726a89d",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T12:12:29.667709Z",
     "start_time": "2024-10-31T12:12:28.622569Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_out_neurons = num_classes\n",
    "model = nn.Sequential(nn.LazyLinear(128), nn.ReLU6(), nn.LazyLinear(num_out_neurons))\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
    "\n",
    "X_tra_feat, Y_tra = torch.FloatTensor(X_tra_feat), torch.LongTensor(Y_tra)\n",
    "X_val_feat, Y_val = torch.FloatTensor(X_val_feat), torch.LongTensor(Y_val)\n",
    "train_loader = DataLoader(TensorDataset(X_tra_feat, Y_tra), batch_size=32, shuffle=True)\n",
    "\n",
    "max_epochs = 20\n",
    "do_train_single_label_cpu(model, optimizer, loss_fn, train_loader, (X_val_feat, Y_val),\n",
    "                          max_epochs, scheduler)"
   ],
   "id": "91aa76b3f918f09f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch-10/20] Test Acc. 95.33%\n",
      "[Epoch-20/20] Test Acc. 95.18%\n",
      "\n",
      "Test Acc. 95.18%\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T02:36:50.193629Z",
     "start_time": "2024-10-31T02:36:50.190902Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "5cb81a8f71f3d915",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
